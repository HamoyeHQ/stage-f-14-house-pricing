{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (20.2.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002747D20BCC8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pip/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002747D20B648>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pip/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002747D211888>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pip/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002747D211708>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pip/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002747D211D48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/pip/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==0.23.4 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (0.23.4)\n",
      "Requirement already satisfied: matplotlib==3.0.3 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (3.0.3)\n",
      "Requirement already satisfied: scipy==1.2.1 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (1.2.1)\n",
      "Requirement already satisfied: scikit-learn==0.22 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (0.22)\n",
      "Requirement already satisfied: tensorflow==2.0 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (2.0.0)\n",
      "Requirement already satisfied: keras==1.2.2 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from pandas==0.23.4) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from pandas==0.23.4) (1.16.5)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from pandas==0.23.4) (2019.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from matplotlib==3.0.3) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from matplotlib==3.0.3) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from matplotlib==3.0.3) (2.4.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from scikit-learn==0.22) (0.13.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.0) (1.33.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.0) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.0) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.0) (1.1.2)\n",
      "Requirement already satisfied: gast==0.2.2 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.0) (0.2.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from tensorflow==2.0) (1.12.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.0) (2.0.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.0) (0.8.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.0) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from tensorflow==2.0) (0.33.6)\n",
      "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.0) (2.0.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.0) (0.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from tensorflow==2.0) (1.11.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.0) (3.13.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow==2.0) (1.0.8)\n",
      "Requirement already satisfied: theano in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from keras==1.2.2) (1.0.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from keras==1.2.2) (5.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib==3.0.3) (41.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.16.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.22.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow==2.0) (2.9.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.23)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (4.6)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.3.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (3.1.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0) (7.2.0)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --user --upgrade pip\n",
    "\n",
    "!pip3 install pandas==0.23.4 matplotlib==3.0.3 scipy==1.2.1 scikit-learn==0.22 tensorflow==2.0 keras==1.2.2 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restart the kernel before you proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as  pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Kubeflow pipelines SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kfp\n",
      "  Downloading kfp-1.1.1.tar.gz (162 kB)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from kfp) (5.1.2)\n",
      "Collecting google-cloud-storage>=1.13.0\n",
      "  Downloading google_cloud_storage-1.32.0-py2.py3-none-any.whl (92 kB)\n",
      "Collecting kubernetes<12.0.0,>=8.0.0\n",
      "  Downloading kubernetes-11.0.0-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied, skipping upgrade: google-auth>=1.6.1 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from kfp) (1.23.0)\n",
      "Collecting requests_toolbelt>=0.8.0\n",
      "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from kfp) (1.2.2)\n",
      "Collecting kfp-server-api<2.0.0,>=0.2.5\n",
      "  Downloading kfp-server-api-1.0.4.tar.gz (51 kB)\n",
      "Requirement already satisfied, skipping upgrade: jsonschema>=3.0.1 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from kfp) (3.0.2)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied, skipping upgrade: click in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from kfp) (7.0)\n",
      "Collecting Deprecated\n",
      "  Downloading Deprecated-1.2.10-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting strip-hints\n",
      "  Downloading strip-hints-0.1.9.tar.gz (30 kB)\n",
      "Collecting docstring-parser>=0.7.3\n",
      "  Downloading docstring_parser-0.7.3.tar.gz (13 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting kfp-pipeline-spec<0.2.0,>=0.1.0\n",
      "  Downloading kfp_pipeline_spec-0.1.2-py3-none-any.whl (21 kB)\n",
      "Collecting google-resumable-media<2.0dev,>=1.0.0\n",
      "  Downloading google_resumable_media-1.1.0-py2.py3-none-any.whl (75 kB)\n",
      "Collecting google-cloud-core<2.0dev,>=1.4.1\n",
      "  Downloading google_cloud_core-1.4.3-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from google-cloud-storage>=1.13.0->kfp) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=14.05.14 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2019.9.11)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.3 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=21.0.0 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (41.4.0)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.24.2 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from google-auth>=1.6.1->kfp) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from google-auth>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from google-auth>=1.6.1->kfp) (4.6)\n",
      "Requirement already satisfied, skipping upgrade: pyrsistent>=0.14.0 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from jsonschema>=3.0.1->kfp) (0.15.4)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from jsonschema>=3.0.1->kfp) (19.2.0)\n",
      "Requirement already satisfied, skipping upgrade: wrapt<2,>=1.10 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from Deprecated->kfp) (1.11.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from strip-hints->kfp) (0.33.6)\n",
      "Collecting google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"\n",
      "  Downloading google_crc32c-1.0.0-cp37-cp37m-win_amd64.whl (36 kB)\n",
      "Collecting google-api-core<2.0.0dev,>=1.19.0\n",
      "  Downloading google_api_core-1.23.0-py2.py3-none-any.whl (91 kB)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage>=1.13.0->kfp) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage>=1.13.0->kfp) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied, skipping upgrade: cffi>=1.0.0 in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp) (1.12.3)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in c:\\users\\miloh\\appdata\\roaming\\python\\python37\\site-packages (from google-api-core<2.0.0dev,>=1.19.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp) (3.13.0)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied, skipping upgrade: pytz in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from google-api-core<2.0.0dev,>=1.19.0->google-cloud-core<2.0dev,>=1.4.1->google-cloud-storage>=1.13.0->kfp) (2019.3)\n",
      "Requirement already satisfied, skipping upgrade: pycparser in c:\\users\\miloh\\appdata\\local\\continuum\\anaconda31\\lib\\site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=1.0.0->google-cloud-storage>=1.13.0->kfp) (2.19)\n",
      "Building wheels for collected packages: kfp, kfp-server-api, strip-hints, docstring-parser\n",
      "  Building wheel for kfp (setup.py): started\n",
      "  Building wheel for kfp (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-1.1.1-py3-none-any.whl size=221433 sha256=767933b861b0ad7de8af044c6cb26094be2f3c1b8bee7730c7ed52d7aa11bfa3\n",
      "  Stored in directory: c:\\users\\miloh\\appdata\\local\\pip\\cache\\wheels\\41\\38\\6c\\29aaec4c314a72c29ef05a82f3c8d0de06d447145d56d24f61\n",
      "  Building wheel for kfp-server-api (setup.py): started\n",
      "  Building wheel for kfp-server-api (setup.py): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.0.4-py3-none-any.whl size=104117 sha256=5091780b84066dc86dd56f1e007248c066ae7b23bae3391a9ce09e4451986982\n",
      "  Stored in directory: c:\\users\\miloh\\appdata\\local\\pip\\cache\\wheels\\1f\\46\\3e\\4c4154156f4278f818e0dc18a82c29f174d2695ec13a396413\n",
      "  Building wheel for strip-hints (setup.py): started\n",
      "  Building wheel for strip-hints (setup.py): finished with status 'done'\n",
      "  Created wheel for strip-hints: filename=strip_hints-0.1.9-py2.py3-none-any.whl size=20999 sha256=9c526d734cb0448a7d34eb4f040efe840634824c3a070cfee22f73754b9584ba\n",
      "  Stored in directory: c:\\users\\miloh\\appdata\\local\\pip\\cache\\wheels\\2d\\b8\\4e\\a3ec111d2db63cec88121bd7c0ab1a123bce3b55dd19dda5c1\n",
      "  Building wheel for docstring-parser (PEP 517): started\n",
      "  Building wheel for docstring-parser (PEP 517): finished with status 'done'\n",
      "  Created wheel for docstring-parser: filename=docstring_parser-0.7.3-py3-none-any.whl size=19236 sha256=8abef0d0bbdfd27c2be31ed17fa6c88955caf16b68753cf1384c58aeb0d54a0c\n",
      "  Stored in directory: c:\\users\\miloh\\appdata\\local\\pip\\cache\\wheels\\ac\\ed\\39\\ecb2e36c2893bb7b1324f6def66a7b3369c0bfc36ed2e07bb3\n",
      "Successfully built kfp kfp-server-api strip-hints docstring-parser\n",
      "Installing collected packages: google-crc32c, google-resumable-media, googleapis-common-protos, google-api-core, google-cloud-core, google-cloud-storage, websocket-client, kubernetes, requests-toolbelt, kfp-server-api, tabulate, Deprecated, strip-hints, docstring-parser, kfp-pipeline-spec, kfp\n",
      "Successfully installed Deprecated-1.2.10 docstring-parser-0.7.3 google-api-core-1.23.0 google-cloud-core-1.4.3 google-cloud-storage-1.32.0 google-crc32c-1.0.0 google-resumable-media-1.1.0 googleapis-common-protos-1.52.0 kfp-1.1.1 kfp-pipeline-spec-0.1.2 kfp-server-api-1.0.4 kubernetes-11.0.0 requests-toolbelt-0.9.1 strip-hints-0.1.9 tabulate-0.8.7 websocket-client-0.57.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021BED431688>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/1a/b4/3940eb932bac1fe5afa553414bc495eaa4f623f227d99de3a6c471edadf5/kfp-1.1.1.tar.gz\n",
      "  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021BED431A08>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/1a/b4/3940eb932bac1fe5afa553414bc495eaa4f623f227d99de3a6c471edadf5/kfp-1.1.1.tar.gz\n",
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "google-api-core 1.23.0 requires six>=1.13.0, but you'll have six 1.12.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# You may need to restart your notebook kernel after updating the kfp sdk\n",
    "!pip3 install kfp --upgrade --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the install was successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'which' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!which dsl-compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'stage-f-14-house-pricing pipeline'        # Name of the experiment in the UI\n",
    "BASE_IMAGE = \"tensorflow/tensorflow:latest-gpu-py3\"    # Base image used for components in the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Kubeflow SDK\n",
    "import kfp\n",
    "from kfp import compiler\n",
    "import kfp.dsl as dsl\n",
    "import kfp.components as comp\n",
    "import os\n",
    "import subprocess\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the outputs are stored\n",
    "out_dir = \"/home/jovyan/House_Pricing_Prediction/data/out/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a pipeline Function\n",
    "## Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miloh\\AppData\\Local\\Continuum\\anaconda31\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated function (or staticmethod) python_component. (This decorator does not seem to be used, so we deprecate it. If you need this decorator, please create an issue at https://github.com/kubeflow/pipelines/issues) -- Deprecated since version 0.2.6.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "@dsl.python_component(\n",
    "    name='preprocess_op',\n",
    "    description='preprocessing function for House Pricing',\n",
    "    base_image=BASE_IMAGE  # you can define the base image here, or when you build in the next step. \n",
    ")\n",
    "\n",
    "\n",
    "def preprocess(data_path):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    import sys, subprocess;\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas==0.23.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn==0.22'])\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import train_test_split  # splitting the data\n",
    "    \n",
    "    # Get data\n",
    "    data = pd.read_csv('https://raw.githubusercontent.com/ugoiloh/stage-f-14-house-pricing/ugoiloh/data/data.csv')\n",
    "    \n",
    "    # drop unneccessary column\n",
    "    data.drop(columns=['date','country', 'statezip', 'street'], inplace=True)\n",
    "    \n",
    "    #Filtering for prices that are not zero.\n",
    "    data = data.query('price != 0')\n",
    "    \n",
    "    #Filtering for houses not zero for number of bedrooms and bathrooms\n",
    "    data = data.query('bedrooms != 0' or 'bathrooms != 0')\n",
    "    \n",
    "    # Converting the city variable to numerical values.\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    data['city'] = le.fit_transform(data['city'])\n",
    "    \n",
    "    #year convert function\n",
    "    def yr_col (col1, col2):\n",
    "        if col1 == 0:\n",
    "            col1 = col2\n",
    "        else:\n",
    "            col1\n",
    "        return col1\n",
    "    \n",
    "    #Change year renovated column with zero entry to the year built.\n",
    "    data['yr_renovated'] = data.apply(lambda x: yr_col(x['yr_renovated'], x['yr_built']), axis =1)\n",
    "    \n",
    "    #Filtering the outliers\n",
    "    data = data[(\n",
    "                (data['price'] <= 2000000) & \n",
    "                (data['price'] > 150000) & \n",
    "                (data['bathrooms'] <= 4.5) & \n",
    "                (data['condition'] > 2) & \n",
    "                (data['sqft_living'] > 700) & \n",
    "                (data['sqft_living'] <= 5000) & \n",
    "                (data['sqft_lot'] <= 50000) & \n",
    "                (data['sqft_above'] <= 5000) &\n",
    "                (data['sqft_basement'] <= 5000) &\n",
    "                (data['bedrooms'] <= 6) \n",
    "                )]\n",
    "    \n",
    "    #Filtering for multicollinearity\n",
    "    data = data.drop(columns=['sqft_living', 'sqft_above'])\n",
    "    \n",
    "    # split the data into X and y\n",
    "    X = data.drop(['price'], axis=1)  # predictor\n",
    "    y = data['price'] # target\n",
    "    \n",
    "    # Split the data into training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    #output file to path\n",
    "    np.savez_compressed(f'{data_path}/preprocessed-data.npz', \n",
    "                       X_train=X_train,\n",
    "                       X_test=X_test,\n",
    "                       y_train=y_train,\n",
    "                       y_test=y_test)\n",
    "    print(\"Preprocessing Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function\n",
    "## Training the data with the Catboost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install catboost\n",
    "!pip3 install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.python_component(\n",
    "    name='train_op',\n",
    "    description='training function for House Pricing',\n",
    "    base_image=BASE_IMAGE  # you can define the base image here, or when you build in the next step. \n",
    ")\n",
    "\n",
    "def train(data_path, model_file):\n",
    "    \n",
    "    # Install all the dependencies inside the function\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    import sys, subprocess;\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'pandas==0.23.4'])\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn==0.22'])\n",
    "    \n",
    "    # import libraries for training\n",
    "    from catboost import CatBoostRegressor\n",
    "    \n",
    "    #load the preprocessed data\n",
    "    preprocessed_data = np.load(f'{data_path}/preprocessed-data.npz')\n",
    "    X_train = preprocessed_data['X_train']\n",
    "    y_train = preprocessed_data['y_train']\n",
    "    \n",
    "    # Instantiating the model \n",
    "    mmodel = CatBoostRegressor(verbose=0, n_estimators=100)\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    #Save the model to the designated \n",
    "    with open(f'{data_path}/{model_file}', 'wb') as file:\n",
    "        pickle.dump(main_model, file)\n",
    "        \n",
    "    print(\"Model Trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.python_component(\n",
    "    name='predict_op',\n",
    "    description='prediction function for House Pricing',\n",
    "    base_image=BASE_IMAGE  # you can define the base image here, or when you build in the next step. \n",
    ")\n",
    "\n",
    "def predict(data_path, model_file):\n",
    "    \n",
    "    import pickle     # python object for (de)serialization\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    from sklearn.metrics import mean_squared_error, r2_score \n",
    "      \n",
    "    # Load the saved trained model\n",
    "    with open((f'{data_path}/{model_file}', 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    \n",
    "    #load the preprocessed data\n",
    "    preprocessed_data = np.load(f'{data_path}/preprocessed-data.npz')\n",
    "    X_test = preprocessed_data['X_test']\n",
    "    y_test = preprocessed_data['y_test']\n",
    "    \n",
    "    #Evaluate the model and print the results\n",
    "    model_pred = model.predict(X_test)\n",
    "    \n",
    "    # print the RMSE\n",
    "    #print('Model \\nRMSE score = {}' .format(np.sqrt(mean_squared_error(y_test, model_pred))))\n",
    "            \n",
    "    # print the RMSE\n",
    "    #print('Model \\nRMSE score = {}' .format(r2_score(y_test, model_pred)))\n",
    "              \n",
    "    print('Model \\nRsquared score: %.2f' % r2_score(y_test, model_pred))\n",
    "    print(\"Model \\nRMSE RMSE_test score: %0.3f\" % np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print(\"Model \\nRMSE_train score: %0.3f\" % np.sqrt(mean_squared_error(y_train, model.predict(x_train))))\n",
    "    \n",
    "    with open(f'{data_path}/model_result.txt', 'w') as result:\n",
    "        result.write(\" Prediction: {},\\nActual: {} \".format(model_pred, y_test))\n",
    "              \n",
    "    print('Prediction has be saved successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocess, train and predict lightweight components.\n",
    "preprocess_op = comp.func_to_container_op(preprocess, base_image=BASE_IMAGE)\n",
    "train_op = comp.func_to_container_op(train , base_image=BASE_IMAGE)\n",
    "predict_op = comp.func_to_container_op(predict , base_image=BASE_IMAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Kubeflow Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load kube config.\n"
     ]
    }
   ],
   "source": [
    "#Create a client to enable communication with the Pipelines API server.\n",
    "client = kfp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain-specific language \n",
    "@dsl.pipeline(\n",
    "    name='House Prediction',\n",
    "    description='End-to-end training to predict the price of a house'\n",
    ")\n",
    "\n",
    "# Define parameters to be fed into pipeline\n",
    "def house_prediction_container_pipeline(\n",
    "    data_path: str,\n",
    "    model_file: str\n",
    "):\n",
    "    \n",
    "    # Define volume to share data between components.\n",
    "    vop = dsl.VolumeOp(\n",
    "    name=\"volume_creation\",\n",
    "    resource_name=\"data-volume\", \n",
    "    size=\"1Gi\", \n",
    "    modes=dsl.VOLUME_MODE_RWO)\n",
    "    \n",
    "    # Create house price preprocessing component\n",
    "    price_preprocessing_container = preprocess_op(data_path).add_pvolumes({data_path: vop.volume})\n",
    "    \n",
    "    # Create house price training component.\n",
    "    price_training_container = train_op(data_path, model_file) \\\n",
    "                                    .add_pvolumes({data_path: price_preprocessing_container.volume})\n",
    "    \n",
    "    # Create price prediction component.\n",
    "    price_predict_container = predict_op(data_path, model_file) \\\n",
    "                                    .add_pvolumes({data_path: price_training_container.pvolume})\n",
    "    \n",
    "    # Print the result of the prediction\n",
    "    House_Price_result_container = dsl.ContainerOp(\n",
    "        name=\"House Price prediction\",\n",
    "        image='library/bash:4.4.23',\n",
    "        pvolumes={data_path: price_predict_container.pvolume},\n",
    "        arguments=['head', f'{data_path}/model_result.txt']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Pipeline\n",
    "Kubeflow Pipelines lets you group pipeline runs by Experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/mnt'\n",
    "MODEL_PATH='house_price_predictor.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = house_price_container_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'House_Price_Prediction'\n",
    "run_name = pipeline_func.__name__ + ' run'\n",
    "\n",
    "arguments = {\"data_path\":DATA_PATH,\n",
    "             \"model_file\":MODEL_PATH}\n",
    "\n",
    "# Compile pipeline to generate compressed YAML definition of the pipeline.\n",
    "kfp.compiler.Compiler().compile(pipeline_func,'{}.zip'.format(experiment_name))\n",
    "\n",
    "# Submit pipeline directly from pipeline function\n",
    "run_result = client.create_run_from_pipeline_func(pipeline_func, \n",
    "                                                  experiment_name=experiment_name, \n",
    "                                                  run_name=run_name, \n",
    "                                                  arguments=arguments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
